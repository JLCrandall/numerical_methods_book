{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Nonlinear Root Finding - Bisection Method\n",
      "\n",
      "The bisection method, sometimes called the binary search method, is a simple method for finding the root, or zero, of a nonlinear equation with one unknown variable. (If the equation is lienar, we can solve for the root algebraically.)\n",
      "\n",
      "If we suppose $f$ is a continuous function defined on the interal $[a,b]$, with $f(a)$ and $f(b)$ of opposite sign (e.g., they appear on opposite sides of the root). There exists a point $p$ within the interval $[a,b]$ with $f(p) = 0$. We start the iteration by choosing a point halfway between $a$ and $b$ and checking the sign of $f(p)$. It will either have the same sign as $f(a)$ or $f(b)$. If the sign of $f(p)$ is the same as $f(a)$. Then $p$ gets set to $a$ and the process is repeated. If the sign of $f(p)$ is the same as $f(b)$, then $p$ gets set to $b$ and the process is repeated.\n",
      "\n",
      "An animation showing the root of the function $f(x) = cos(x) - x^3$ converging to a tolerance of $0.05$ follows:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### INTERACTIVE MODEL ###"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Psuedocode for Bisection Method\n",
      "\n",
      "The bisection method finds a solution to $f(x) = 0$ where $f$ is continuously defined on the interval $[a,b]$ and $f(a)$ and $f(b)$ have opposite signs:\n",
      "\n",
      "  1. Set $i = 1$\n",
      "  1. Set $FA = f(a)$\n",
      "  1. While $i \\leq $max iterations, do Steps A-F\n",
      "      1. Set $p = a+ \\frac{(b-a)}{2}$\n",
      "      1. Set $FP = f(p)$\n",
      "      1. If $FP = 0$ or $\\frac{(b-a)}{2}$ < TOL, end program, output $p$ as the root.\n",
      "      1. If sign of $(FA) \\cdot$sign$(FP) > 0$, then do steps a-b, else do Step E\n",
      "          1. $a = p$\n",
      "          1. $FA = FP$\n",
      "      1. Else, $b = p$\n",
      "      1. Set $i = i+1$\n",
      "  1. Print \"Method failed to converge after 'max iterations'.\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "def f(x):\n",
      "    return np.cos(x)-x**3\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Other stop procedures and convergence of the Bisection Method.\n",
      "\n",
      "Other stopping procedure can be applied at Step C in the previous pseudocode. For example we can select a tolerance of $\\in$ and generate $p_1, p_2, ... p_N$ until one of the following conditions is met.\n",
      "\n",
      "$ |p_N - p_{N-1}| < \\in$\n",
      "\n",
      "$\\frac{|P_N - p_{N-1}|}{|p_N|} < \\in$\n",
      "\n",
      "$|f(p_N)| < \\in$\n",
      "\n",
      "The Biesection method has the advantage that as long as the root is bounded by the interval $[a,b]$, it will always converge. It has the disadvantage that convergence can be very slow and a good intermediate approximation to the root can be inadvertently discarded. This method is most useful when used to get an initial very rough approximation to a root and then combine it with a method that has faster convergence to get a better approximation to the root. We will talk about these other methods in the upcoming sections.\n",
      "\n",
      "Let's have a look at the convergence rate of this method:\n",
      "\n",
      "Suppose that $f \\in C[a,b] $ and $f(a)\\cdot f(b) < 0$. The Bisection method generates a sequence $\\{p_n - p\\}_{n=1}^\\infty$ approximating a zero $p$ with $f$ with:\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp; $|p_n -p| \\leq \\frac{b-a}{2^n}$, when $n\\geq 1$. \n",
      "\n",
      "**Proof:** For each $n\\geq 1$, we have\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp; $b_n - a_n = \\frac{1}{2^{n-1}} (b-a) $ and $p \\in (a_n, b_n)$\n",
      "\n",
      "Since $p_n = \\frac{1}{2}(a_n + b_n)$ for all $n \\geq 1$, then \n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp; $|p_n - p| < \\frac{1}{2}(b_n - a_n) = \\frac{b-a}{2^n}$\n",
      "\n",
      "Since, \n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp; $|p_n - p| \\leq (b-a)\\frac{1}{2^n}$\n",
      "\n",
      "the sequence $\\{p_n\\}_{n=1}^\\infty$ converges to $p$ with rate of convergence $O(\\frac{1}{2^n})$, i.e. \n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp; $p_n = p + O(\\frac{1}{2^n})$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Nonlinear Root Finding - Newton-Raphson (Newton's Method)\n",
      "\n",
      "The Newton-Raphson method is most commonly used when a function of a single variable is defined mathematically (not a result of other numerical computations) and the derivative of the function can be easily evaluated. The method approximates a function by it's tangent line at a point to get successively better estimates of the root.\n",
      "\n",
      "For a function\n",
      "\n",
      "$f(x) = 0$\n",
      "\n",
      "The general formula is as follows:\n",
      "\n",
      "$x_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)}$\n",
      "\n",
      "An example: One iteration of the function $f(x) = x^2 - 25$.\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Function f(x) = x^2 - 25; x0 = 6\n",
      "\n",
      "def derivative(f, x, h):\n",
      "      return (f(x+h) - f(x-h)) / (2.0*h)  # might want to return a small non-zero if ==0\n",
      "\n",
      "def quadratic(x):\n",
      "    return x**2 - 25 \n",
      "\n",
      "def solve(f, x0, h):\n",
      "    lastX = x0\n",
      "    nextX = lastX + 10* h  # \"different than lastX so loop starts\n",
      "    while (abs(lastX - nextX) > h):  # this is how you end the loop - note use of abs()\n",
      "        newY = f(nextX)                     # just to see what happens\n",
      "        print \"f(\", nextX, \") = \", newY     # print out progress to keep track\n",
      "        lastX = nextX\n",
      "        nextX = lastX - newY / derivative(f, lastX, h)  # update estimate using N-R\n",
      "    return nextX\n",
      "\n",
      "xFound = solve(quadratic, 6, 0.01)    # call the solver\n",
      "print \"solution: x = \", xFound        # print the result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "f( 6.1 ) =  12.21\n",
        "f( 5.09918032787 ) =  1.00164001612\n",
        "f( 5.00096454104 ) =  0.00964634078157\n",
        "solution: x =  5.00000009302\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Graph, need modules loaded ###"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Stop Condition\n",
      "\n",
      "We continue the successive iterations until some critical tolerance criterion has been met. The tolerance criterion can be defined as follows:\n",
      "\n",
      "$|x_{n+1} - x_n| < \\epsilon$\n",
      "\n",
      "An animation showing the root of the function $f(x) = cos(x) - x^3$ converging to a tolerance of 0.001. An initial guess of 0.5 was used."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Interactive Graphic ###"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Pseudocode for Newton's Method.\n",
      "\n",
      "To find a solution to f(x) = 0 given an initial guess $p_0$:\n",
      "\n",
      "  1. Set $i = 1$\n",
      "  1. While $i \\leq $max iterations, do steps a-d\n",
      "    1. Set $p=p_0 - f(p_0)/f'(p_0)$\n",
      "    1. If $|p - p_0| < TOL$, end program and out $p$ as approximate root\n",
      "    1. Set $i = i + 1$\n",
      "    1. Set $p_0 = p$\n",
      "  1. Print \"Method failed to converge after 'max iterations'.\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "def f(x):\n",
      "    return np.cos(x) - x**3\n",
      "def df(x):\n",
      "    return -3*x**2 - np.sin(x)\n",
      "\n",
      "def newton(x,n):\n",
      "    for i in range(n):\n",
      "        if df(x) == 0:\n",
      "            return x\n",
      "        x = x-(f(x)/df(x))\n",
      "    return x\n",
      "\n",
      "print newton(.5,10) \n",
      "#change .5 and 10 to be the initial guess and number of iterations repsectively"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.865474033102\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Convergence of Newton's Method.\n",
      "\n",
      "Assume that Newton's $x_{k+1}$ iteration converges to $x^*$ with $f(x^*) \\neq 0$. If we define\n",
      "\n",
      "$x_k = x^* + \\epsilon_k$\n",
      "\n",
      "and take the Taylor series expansion about $x^*$ we have\n",
      "\n",
      "$f(x_k) = f(x^*) + f'(x^*)\\epsilon_k + \\frac{1}{2} f''(x^*)\\epsilon_k^2 + ...$\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$= f'(x^*)\\epsilon_k + \\frac{1}{2}f''(x^*)\\epsilon_k^2 + ...$\n",
      "\n",
      "$f'(x_k)= f'(x^*)+f''(x^*)\\epsilon_k + ...$\n",
      "\n",
      "But,\n",
      "\n",
      "$\\epsilon_{k+1} = \\epsilon_k + (x_{k+1} - x_k)$\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$=\\epsilon_k - \\frac{f(x_k)}{f'(x_k)}$\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\approx \\epsilon_k - \\frac{f'(x^*)\\epsilon_k + \\frac{1}{2}f''(x^*)\\epsilon_k^2}{f'(x^*)+f''(x^*)\\epsilon_k}$\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\approx \\frac{f''(x^*)}{2f'(x^*)}\\epsilon_k^2$\n",
      "\n",
      "The last equation implies that Newton's method converges *quadratically*. That is, near a root, the number of significant digits approximately doubles with each step. This is a very strong convergence property and makes Newton's method the root finding method of choice for any function whose derivative can be evaluated efficiently and is continuous near the root."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Nonlinear Root Finding - Secant Method\n",
      "\n",
      "In the last section we discussed Newton's method for root finding. We said that although Newton's method has some very strong convergence properties, one disadvantage is the need to evaluate $f'(x)$, which can sometimes be messy. In order to circumvent this derivative calculation we introduce a slight variation. Recall, that by definition:\n",
      "\n",
      "$f'(x_{n-1}) = lim_{x\\rightarrow x_{n-1}}\\frac{f(x_{n-1})-f(x_{n-2})}{x_{n-2}-x_{n-1}}$.\n",
      "\n",
      "This technique is called the *secant method*. Here we need two initial approximations $x_0$ and $x_1$, although they do not need to be bound by the root."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Secant Method Examples\n",
      "\n",
      "An animation showing the root of the function $f(x) = cos(x) - x^3$ converging to a tolerance of 0.05. The initial guesses of 0.1 and 1.4 were used."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### INTERATIVE GRAPHIC ###"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is another simulation for the same problem, but this time the initial guesses are 1.2 and 1.4. This demonstrates that the secant method guesse do not have to be bound by the root."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### INTERATIVE GRAPHIC ###"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Pseudocode for Secant Method.\n",
      "\n",
      "To find a solution to $f(x) = 0$ given initial guesses of $p_0$ and $p_1$:\n",
      "\n",
      "  1. Set $i = 2$\n",
      "  1. Set $q_0 = f(p_0)$\n",
      "  1. set $q_1 = f(p_1)$\n",
      "  1. While $i \\leq max iterations$, do Steps A-H\n",
      "    1. Set $p = p_1 - q_1(p_1 - p_0) / (q_1 - q_0)$\n",
      "    1. If $|p - p_1| < TOL$, end program and out $p$ as approximate root.\n",
      "    1. Set $i = i+1$\n",
      "    1. Set $p_0 = p_1$\n",
      "    1. Set $q_0 = q_1$\n",
      "    1. Set $p_1 = p$\n",
      "    1. Set $q_1 = f(p)$\n",
      "    1. Set $i = i + 1$\n",
      "  1. Print \"Method failed to converge after 'max iterations'.\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "def f(x):\n",
      "    return np.cos(x) - x**3\n",
      "\n",
      "def secant(p0, p1, n):\n",
      "    for i in range(n):\n",
      "        if f(p1)-f(p0) == 0:\n",
      "            return p1\n",
      "        p_temp = p1 - (f(p1)*(p1-p0)*1.0)/(f(p1)-f(p0))\n",
      "        p0 = p1\n",
      "        p1 = p_temp\n",
      "    return p1\n",
      "\n",
      "print secant(1.2, 1.4, 10)\n",
      "#Change 1.2 and 1.4 for initial guesses and 10 for the number of iterations"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.865474033102\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Convergence and Other Comments.\n",
      "\n",
      "It can be shown that the order of convergence of the secant method is the \"golden ratio\"\n",
      "\n",
      "$\\alpha = \\frac{1+\\sqrt{5}}{2} \\approx 1.618$\n",
      "\n",
      "This means that the error follows the following relationship:\n",
      "\n",
      "$lim_{k\\rightarrow \\infty} |\\epsilon_{k+1}| \\approx \\times |\\epsilon_k|^\\alpha$\n",
      "\n",
      "The secant method has the disadvantage that the root does not necessarily remain bracketed. For functions that are not sufficiently continuous, the algorithm is not guaranteed to converge. Local behavior might send it off toward infinity. There is a slight modification to the secant method called the *false position method* that will keep the root bracketed and therefore guarantee convergence, but at a slower rate. A better method to guarantee convergence would be to combine the secant method with the bisection method, therefore we will not discuss the false position method."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Hybrid Methods.\n",
      "\n",
      "Hybrid methods simply combine two or more root finding methods to create a robust algorithm. Here I have combined the bisection method with the secant method. The bisection method is used to get near the root, then the secant method is used to polish it off. This is for the same function used in previous examples $f(x) = cos(x) - x^3$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "def f(x):\n",
      "    return np.cos(x) - x**3\n",
      "xrange = [0,1.5]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### INTERATIVE GRAPHIC ###"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}