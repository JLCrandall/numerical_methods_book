{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Nonlinear Root Finding - Bisection Method\n",
      "\n",
      "The bisection method, sometimes called the binary search method, is a simple method for finding the root, or zero, of a nonlinear equation with one unknown variable. (If the equation is lienar, we can solve for the root algebraically.)\n",
      "\n",
      "If we suppose $f$ is a continuous function defined on the interal $[a,b]$, with $f(a)$ and $f(b)$ of opposite sign (e.g., they appear on opposite sides of the root). There exists a point $p$ within the interval $[a,b]$ with $f(p) = 0$. We start the iteration by choosing a point halfway between $a$ and $b$ and checking the sign of $f(p)$. It will either have the same sign as $f(a)$ or $f(b)$. If the sign of $f(p)$ is the same as $f(a)$. Then $p$ gets set to $a$ and the process is repeated. If the sign of $f(p)$ is the same as $f(b)$, then $p$ gets set to $b$ and the process is repeated.\n",
      "\n",
      "An animation showing the root of the function $f(x) = cos(x) - x^3$ converging to a tolerance of $0.05$ follows:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### INTERACTIVE MODEL ###"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Psuedocode for Bisection Method\n",
      "\n",
      "The bisection method finds a solution to $f(x) = 0$ where $f$ is continuously defined on the interval $[a,b]$ and $f(a)$ and $f(b)$ have opposite signs:\n",
      "\n",
      "  1. Set $i = 1$\n",
      "  1. Set $FA = f(a)$\n",
      "  1. While $i \\leq $max iterations, do Steps A-F\n",
      "      1. Set $p = a+ \\frac{(b-a)}{2}$\n",
      "      1. Set $FP = f(p)$\n",
      "      1. If $FP = 0$ or $\\frac{(b-a)}{2}$ < TOL, end program, output $p$ as the root.\n",
      "      1. If sign of $(FA) \\cdot$sign$(FP) > 0$, then do steps a-b, else do Step E\n",
      "          1. $a = p$\n",
      "          1. $FA = FP$\n",
      "      1. Else, $b = p$\n",
      "      1. Set $i = i+1$\n",
      "  1. Print \"Method failed to converge after 'max iterations'.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Other stop procedures and convergence of the Bisection Method.\n",
      "\n",
      "Other stopping procedure can be applied at Step C in the previous pseudocode. For example we can select a tolerance of $\\in$ and generate $p_1, p_2, ... p_N$ until one of the following conditions is met.\n",
      "\n",
      "$ |p_N - p_{N-1}| < \\in$\n",
      "\n",
      "$\\frac{|P_N - p_{N-1}|}{|p_N|} < \\in$\n",
      "\n",
      "$|f(p_N)| < \\in$\n",
      "\n",
      "The Biesection method has the advantage that as long as the root is bounded by the interval $[a,b]$, it will always converge. It has the disadvantage that convergence can be very slow and a good intermediate approximation to the root can be inadvertently discarded. This method is most useful when used to get an initial very rough approximation to a root and then combine it with a method that has faster convergence to get a better approximation to the root. We will talk about these other methods in the upcoming sections.\n",
      "\n",
      "Let's have a look at the convergence rate of this method:\n",
      "\n",
      "Suppose that $f \\in C[a,b] $ and $f(a)\\cdot f(b) < 0$. The Bisection method generates a sequence $\\{p_n - p\\}_{n=1}^\\infty$ approximating a zero $p$ with $f$ with:\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp; $|p_n -p| \\leq \\frac{b-a}{2^n}$, when $n\\geq 1$. \n",
      "\n",
      "**Proof:** For each $n\\geq 1$, we have\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp; $b_n - a_n = \\frac{1}{2^{n-1}} (b-a) $ and $p \\in (a_n, b_n)$\n",
      "\n",
      "Since $p_n = \\frac{1}{2}(a_n + b_n)$ for all $n \\geq 1$, then \n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp; $|p_n - p| < \\frac{1}{2}(b_n - a_n) = \\frac{b-a}{2^n}$\n",
      "\n",
      "Since, \n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp; $|p_n - p| \\leq (b-a)\\frac{1}{2^n}$\n",
      "\n",
      "the sequence $\\{p_n\\}_{n=1}^\\infty$ converges to $p$ with rate of convergence $O(\\frac{1}{2^n})$, i.e. \n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp; $p_n = p + O(\\frac{1}{2^n})$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Nonlinear Root Finding - Newton-Raphson (Newton's Method)\n",
      "\n",
      "The Newton-Raphson method is most commonly used when a function of a single variable is defined mathematically (not a result of other numerical computations) and the derivative of the function can be easily evaluated. The method approximates a function by it's tangent line at a point to get successively better estimates of the root.\n",
      "\n",
      "For a function\n",
      "\n",
      "$f(x) = 0$\n",
      "\n",
      "The general formula is as follows:\n",
      "\n",
      "$x_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)}$\n",
      "\n",
      "An example: One iteration of the function $f(x) = x^2 - 25$.\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Function f(x) = x^2 - 25; x0 = 6\n",
      "\n",
      "def derivative(f, x, h):\n",
      "      return (f(x+h) - f(x-h)) / (2.0*h)  # might want to return a small non-zero if ==0\n",
      "\n",
      "def quadratic(x):\n",
      "    return x**2 - 25 \n",
      "\n",
      "def solve(f, x0, h):\n",
      "    lastX = x0\n",
      "    nextX = lastX + 10* h  # \"different than lastX so loop starts\n",
      "    while (abs(lastX - nextX) > h):  # this is how you end the loop - note use of abs()\n",
      "        newY = f(nextX)                     # just to see what happens\n",
      "        print \"f(\", nextX, \") = \", newY     # print out progress to keep track\n",
      "        lastX = nextX\n",
      "        nextX = lastX - newY / derivative(f, lastX, h)  # update estimate using N-R\n",
      "    return nextX\n",
      "\n",
      "xFound = solve(quadratic, 6, 0.01)    # call the solver\n",
      "print \"solution: x = \", xFound        # print the result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "f( 6.1 ) =  12.21\n",
        "f( 5.09918032787 ) =  1.00164001612\n",
        "f( 5.00096454104 ) =  0.00964634078157\n",
        "solution: x =  5.00000009302\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Graph, need modules loaded ###"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Stop Condition\n",
      "\n",
      "We continue the successive iterations until some critical tolerance criterion has been met. The tolerance criterion can be defined as follows:\n",
      "\n",
      "$|x_{n+1} - x_n| < \\epsilon$\n",
      "\n",
      "An animation showing the root of the function $f(x) = cos(x) - x^3$ converging to a tolerance of 0.001. An initial guess of 0.5 was used."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Interactive Graphic ###"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Pseudocode for Newton's Method.\n",
      "\n",
      "To find a solution to f(x) = 0 given an initial guess $p_0$:\n",
      "\n",
      "  1. Set $i = 1$\n",
      "  1. While $i \\leq $max iterations, do steps a-d\n",
      "    1. Set $p=p_0 - f(p_0)/f'(p_0)$\n",
      "    1. If $|p - p_0| < TOL$, end program and out $p$ as approximate root\n",
      "    1. Set $i = i + 1$\n",
      "    1. Set $p_0 = p$\n",
      "  1. Print \"Method failed to converge after 'max iterations'.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Convergence of Newton's Method.\n",
      "\n",
      "Assume that Newton's $x_{k+1}$ iteration converges to $x^*$ with $f(x^*) \\neq 0$. If we define\n",
      "\n",
      "$x_k = x^* + \\epsilon_k$\n",
      "\n",
      "and take the Taylor series expansion about $x^*$ we have\n",
      "\n",
      "$f(x_k) = f(x^*) + f'(x^*)\\epsilon_k + \\frac{1}{2} f''(x^*)\\epsilon_k^2 + ...$\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$= f'(x^*)\\epsilon_k + \\frac{1}{2}f''(x^*)\\epsilon_k^2 + ...$\n",
      "\n",
      "$f'(x_k)= f'(x^*)+f''(x^*)\\epsilon_k + ...$\n",
      "\n",
      "But,\n",
      "\n",
      "$\\epsilon_{k+1} = \\epsilon_k + (x_{k+1} - x_k)$\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$=\\epsilon_k - \\frac{f(x_k)}{f'(x_k)}$\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\approx \\epsilon_k - \\frac{f'(x^*)\\epsilon_k + \\frac{1}{2}f''(x^*)\\epsilon_k^2}{f'(x^*)+f''(x^*)\\epsilon_k}$\n",
      "\n",
      "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\approx \\frac{f''(x^*)}{2f'(x^*)}\\epsilon_k^2$\n",
      "\n",
      "The last equation implies that Newton's method converges *quadratically*. That is, near a root, the number of significant digits approximately doubles with each step. This is a very strong convergence property and makes Newton's method the root finding method of choice for any function whose derivative can be evaluated efficiently and is continuous near the root."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}